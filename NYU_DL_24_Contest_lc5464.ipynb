{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Uninstall potentially conflicting packages\n",
        "!pip uninstall -y transformers accelerate unsloth torch torchvision torchaudio\n",
        "\n",
        "# Install base packages\n",
        "!pip install unsloth\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q transformers accelerate peft\n",
        "!pip install -q datasets evaluate bitsandbytes trl\n",
        "!pip install -q torch torchvision torchaudio\n",
        "\n",
        "# Install Colab-optimized unsloth\n",
        "!pip uninstall unsloth -y\n",
        "!pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "\n",
        "# Install other tools\n",
        "!pip install pandas scikit-learn\n",
        "!pip install -q ipywidgets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKxfGTnfq2Sn",
        "outputId": "71fc0fa7-65ac-49e2-eab4-81e7bfca5311",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.44.2\n",
            "Uninstalling transformers-4.44.2:\n",
            "  Successfully uninstalled transformers-4.44.2\n",
            "Found existing installation: accelerate 0.34.2\n",
            "Uninstalling accelerate-0.34.2:\n",
            "  Successfully uninstalled accelerate-0.34.2\n",
            "\u001b[33mWARNING: Skipping unsloth as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch 2.5.0+cu121\n",
            "Uninstalling torch-2.5.0+cu121:\n",
            "  Successfully uninstalled torch-2.5.0+cu121\n",
            "Found existing installation: torchvision 0.20.0+cu121\n",
            "Uninstalling torchvision-0.20.0+cu121:\n",
            "  Successfully uninstalled torchvision-0.20.0+cu121\n",
            "Found existing installation: torchaudio 2.5.0+cu121\n",
            "Uninstalling torchaudio-2.5.0+cu121:\n",
            "  Successfully uninstalled torchaudio-2.5.0+cu121\n",
            "Collecting unsloth\n",
            "  Downloading unsloth-2024.11.5-py3-none-any.whl.metadata (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth-zoo>=2024.11.1 (from unsloth)\n",
            "  Downloading unsloth_zoo-2024.11.4-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting torch>=2.4.0 (from unsloth)\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting bitsandbytes (from unsloth)\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.1)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting transformers>=4.46.1 (from unsloth)\n",
            "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.16.0 (from unsloth)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.44.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\n",
            "Collecting accelerate>=0.34.1 (from unsloth)\n",
            "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
            "  Downloading trl-0.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.13.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.24.7)\n",
            "Collecting hf-transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.10.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (2024.9.11)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.46.1->unsloth)\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.3)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth) (0.2.0)\n",
            "Downloading unsloth-2024.11.5-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.8/161.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.12.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2024.11.4-py3-none-any.whl (30 kB)\n",
            "Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparations\n",
        "------"
      ],
      "metadata": {
        "id": "uIWN2AazbCtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Environment setup\n",
        "import os\n",
        "import warnings\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import gc\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "import transformers\n",
        "import accelerate\n",
        "\n",
        "# Print versions\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Transformers version: {transformers.__version__}\")\n",
        "print(f\"Accelerate version: {accelerate.__version__}\")\n",
        "\n",
        "# Configure environment\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "warnings.filterwarnings('ignore')\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# Set random seeds\n",
        "def set_seeds(seed=3407):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Memory management utilities\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "def print_gpu_utilization():\n",
        "    print(\"\\nGPU Memory Usage:\")\n",
        "    !nvidia-smi | grep -E \"Memory|Volatile\""
      ],
      "metadata": {
        "id": "q2ADdar0bCBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "set up wandb"
      ],
      "metadata": {
        "id": "bBRNJ9cqJqjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --upgrade\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "IuwYk1ySIpp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "750ae241-1c6f-4262-c12f-bf21624b3501"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define the sweep"
      ],
      "metadata": {
        "id": "nXDBvaR3JuKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }\n",
        "\n",
        "metric = {\n",
        "    'name': 'loss',\n",
        "    'goal': 'minimize'\n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "parameters_dict = {\n",
        "    'learning_rate:': {\n",
        "        'distribution': 'log_uniform',\n",
        "        'min': 1e-5,\n",
        "        'max': 1e-3\n",
        "        },\n",
        "    'warmup_ratio': {\n",
        "        'values': [0.05, 0.1, 0.2]\n",
        "        },\n",
        "    'weight_decay': {\n",
        "        'values': [0.01, 0.03, 0.05]\n",
        "        },\n",
        "    'per_device_train_batch_size': {\n",
        "        'values': [4, 8, 16, 32]\n",
        "        },\n",
        "    'gradient_accumulation_steps': {\n",
        "        'values': [2, 4, 8]\n",
        "        },\n",
        "    'epochs': {\n",
        "        'value': 1\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ],
      "metadata": {
        "id": "YkUe7Y3FJwjE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ],
      "metadata": {
        "id": "cE0zTn7sRRHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d86f25-e72f-42f5-9a07-244b115b4218"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
            " 'parameters': {'epochs': {'value': 1},\n",
            "                'gradient_accumulation_steps': {'values': [2, 4, 8]},\n",
            "                'learning_rate:': {'distribution': 'log_uniform',\n",
            "                                   'max': 0.001,\n",
            "                                   'min': 1e-05},\n",
            "                'per_device_train_batch_size': {'values': [4, 8, 16, 32]},\n",
            "                'warmup_ratio': {'values': [0.05, 0.1, 0.2]},\n",
            "                'weight_decay': {'values': [0.01, 0.03, 0.05]}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define class\n",
        "---"
      ],
      "metadata": {
        "id": "Z6hC7qnObJHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XZk6B1XqqQkM",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "class MathVerificationTrainer:\n",
        "    def __init__(self, max_seq_length=2048, save_dir='/content/drive/MyDrive/math_verification_sweep'):\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.save_dir = save_dir\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.train_dataset = None\n",
        "        self.eval_dataset = None\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "\n",
        "    def setup_model(self):\n",
        "        clear_memory()\n",
        "        print(\"Loading model...\")\n",
        "\n",
        "        try:\n",
        "            model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "                model_name=\"unsloth/Meta-Llama-3.1-8B\",\n",
        "                max_seq_length=self.max_seq_length,\n",
        "                load_in_4bit=True,\n",
        "            )\n",
        "\n",
        "            # Updated LoRA configuration\n",
        "            model = FastLanguageModel.get_peft_model(\n",
        "                model,\n",
        "                r=16,\n",
        "                target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "                lora_alpha=16,\n",
        "                lora_dropout=0.1,\n",
        "                bias=\"none\",\n",
        "                use_gradient_checkpointing=True,\n",
        "                random_state=3407,\n",
        "                use_rslora=True,\n",
        "            )\n",
        "\n",
        "            self.model = model\n",
        "            self.tokenizer = tokenizer\n",
        "            print(\"Model loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def prepare_datasets(self, max_samples=1000):\n",
        "        clear_memory()\n",
        "        print(\"Preparing datasets...\")\n",
        "\n",
        "        try:\n",
        "            dataset = load_dataset(\n",
        "                \"ad6398/nyu-dl-teach-maths-comp\",\n",
        "                split='train',\n",
        "                streaming=True\n",
        "            )\n",
        "\n",
        "            train_data = list(dataset.take(max_samples))\n",
        "\n",
        "            train_idx, val_idx = train_test_split(\n",
        "                range(len(train_data)),\n",
        "                test_size=0.1,\n",
        "                random_state=3407\n",
        "            )\n",
        "\n",
        "            def process_example(example):\n",
        "                prompt = (\n",
        "                    \"Analyze this mathematics problem and solution:\\n\\n\"\n",
        "                    f\"Question: {example['question']}\\n\"\n",
        "                    f\"Student's Answer: {example['answer']}\\n\"\n",
        "                    \"Let's verify this step by step:\\n\"\n",
        "                    f\"{example.get('solution', 'Analyzing...')}\\n\"\n",
        "                    f\"Is the answer correct? {str(example['is_correct'])}\"\n",
        "                ) + self.tokenizer.eos_token\n",
        "\n",
        "                return {\"text\": prompt}\n",
        "\n",
        "            train_examples = [process_example(train_data[i]) for i in train_idx]\n",
        "            eval_examples = [process_example(train_data[i]) for i in val_idx]\n",
        "\n",
        "            self.train_dataset = Dataset.from_list(train_examples)\n",
        "            self.eval_dataset = Dataset.from_list(eval_examples)\n",
        "\n",
        "            del train_data, train_examples, eval_examples\n",
        "            clear_memory()\n",
        "\n",
        "            print(f\"Datasets prepared! Train size: {len(self.train_dataset)}, Eval size: {len(self.eval_dataset)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preparing datasets: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def setup_training_args(self):\n",
        "        return TrainingArguments(\n",
        "            output_dir=os.path.join(self.save_dir, \"checkpoints\"),\n",
        "            per_device_train_batch_size=2,\n",
        "            gradient_accumulation_steps=8,\n",
        "            warmup_ratio=0.1,\n",
        "            num_train_epochs=3,\n",
        "            learning_rate=1e-4,\n",
        "            fp16=True,  # Updated to always use fp16\n",
        "            logging_steps=10,\n",
        "            optim=\"adamw_torch\",  # Updated optimizer\n",
        "            weight_decay=0.05,\n",
        "            lr_scheduler_type=\"cosine\",\n",
        "            seed=3407,\n",
        "            evaluation_strategy=\"steps\",\n",
        "            eval_steps=50,\n",
        "            save_strategy=\"steps\",\n",
        "            save_steps=50,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            gradient_checkpointing=True,\n",
        "            max_grad_norm=0.3,\n",
        "            report_to=\"none\",\n",
        "            remove_unused_columns=True,\n",
        "            dataloader_pin_memory=False\n",
        "        )\n",
        "\n",
        "    def train(self):\n",
        "        clear_memory()\n",
        "        print(\"Starting training...\")\n",
        "\n",
        "        try:\n",
        "            trainer = SFTTrainer(\n",
        "                model=self.model,\n",
        "                tokenizer=self.tokenizer,\n",
        "                train_dataset=self.train_dataset,\n",
        "                eval_dataset=self.eval_dataset,\n",
        "                dataset_text_field=\"text\",\n",
        "                max_seq_length=self.max_seq_length,\n",
        "                dataset_num_proc=2,\n",
        "                packing=False,\n",
        "                args=self.setup_training_args()\n",
        "            )\n",
        "\n",
        "            trainer.train()\n",
        "\n",
        "            final_save_path = os.path.join(self.save_dir, \"final_model\")\n",
        "            self.model.save_pretrained(final_save_path)\n",
        "            self.tokenizer.save_pretrained(final_save_path)\n",
        "            print(f\"Training completed! Model saved to {final_save_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during training: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def sweep(self):\n",
        "        clear_memory()\n",
        "        print(\"Starting training...\")\n",
        "\n",
        "        wandb.init()\n",
        "        config = wandb.config\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=os.path.join(self.save_dir, \"checkpoints\"),\n",
        "            per_device_train_batch_size=config.per_device_train_batch_size,\n",
        "            gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
        "            warmup_ratio=config.warmup_ratio,\n",
        "            num_train_epochs=config.epochs,\n",
        "            learning_rate=config.learning_rate,\n",
        "            fp16=True,  # Updated to always use fp16\n",
        "            logging_steps=10,\n",
        "            optim=\"adamw_torch\",  # Updated optimizer\n",
        "            weight_decay=config.weight_decay,\n",
        "            lr_scheduler_type=\"cosine\",\n",
        "            seed=3407,\n",
        "            evaluation_strategy=\"steps\",\n",
        "            eval_steps=50,\n",
        "            save_strategy=\"steps\",\n",
        "            save_steps=50,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            gradient_checkpointing=True,\n",
        "            max_grad_norm=0.3,\n",
        "            report_to=\"wandb\",\n",
        "            remove_unused_columns=True,\n",
        "            dataloader_pin_memory=False,\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            trainer = SFTTrainer(\n",
        "                model=self.model,\n",
        "                tokenizer=self.tokenizer,\n",
        "                train_dataset=self.train_dataset,\n",
        "                eval_dataset=self.eval_dataset,\n",
        "                dataset_text_field=\"text\",\n",
        "                max_seq_length=self.max_seq_length,\n",
        "                dataset_num_proc=2,\n",
        "                packing=False,\n",
        "                args=self.setup_training_args()\n",
        "            )\n",
        "\n",
        "            trainer.train()\n",
        "\n",
        "            final_save_path = os.path.join(self.save_dir, \"final_model\")\n",
        "            self.model.save_pretrained(final_save_path)\n",
        "            self.tokenizer.save_pretrained(final_save_path)\n",
        "            print(f\"Training completed! Model saved to {final_save_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during training: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def generate_predictions(self, test_data):\n",
        "        clear_memory()\n",
        "        print(\"Generating predictions...\")\n",
        "\n",
        "        try:\n",
        "            FastLanguageModel.for_inference(self.model)\n",
        "            predictions = []\n",
        "\n",
        "            for i, example in enumerate(test_data):\n",
        "                if i % 50 == 0:  # More frequent updates\n",
        "                    print(f\"Processing example {i}/{len(test_data)}\")\n",
        "                    clear_memory()\n",
        "\n",
        "                prompt = (\n",
        "                    \"Analyze this mathematics problem and solution:\\n\\n\"\n",
        "                    f\"Question: {example['question']}\\n\"\n",
        "                    f\"Student's Answer: {example['answer']}\\n\"\n",
        "                    \"Is this answer correct (True/False)?\\n\"\n",
        "                )\n",
        "\n",
        "                inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "                with torch.inference_mode():\n",
        "                    outputs = self.model.generate(\n",
        "                        **inputs,\n",
        "                        max_new_tokens=64,\n",
        "                        temperature=0.7,\n",
        "                        top_p=0.9,\n",
        "                        do_sample=True,\n",
        "                        use_cache=True\n",
        "                    )\n",
        "\n",
        "                response = self.tokenizer.batch_decode(\n",
        "                    [outputs[0][inputs['input_ids'].shape[1]:]],\n",
        "                    skip_special_tokens=True\n",
        "                )[0].strip().lower()\n",
        "\n",
        "                predictions.append(\"true\" in response)\n",
        "\n",
        "            return predictions\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating predictions: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def create_submission(self):\n",
        "        print(\"Creating submission file...\")\n",
        "        try:\n",
        "            test_dataset = load_dataset(\"ad6398/nyu-dl-teach-maths-comp\")['test']\n",
        "            predictions = self.generate_predictions(test_dataset)\n",
        "\n",
        "            submission_df = pd.DataFrame({\n",
        "                'ID': range(len(predictions)),\n",
        "                'is_correct': predictions\n",
        "            })\n",
        "\n",
        "            submission_path = os.path.join(self.save_dir, 'submission.csv')\n",
        "            submission_df.to_csv(submission_path, index=False)\n",
        "            print(f\"Submission saved to {submission_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating submission: {str(e)}\")\n",
        "            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameters sweeping\n",
        "------"
      ],
      "metadata": {
        "id": "6MyPxv-EImbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial the sweep\n",
        "-----"
      ],
      "metadata": {
        "id": "Zrbq99E0Redc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"math_verification\")"
      ],
      "metadata": {
        "id": "_Q0-DB4jRggc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c21e6ec-18c9-404b-efc4-d00cb8b31271"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. 'learning_rate:' does not match '^^[A-Za-z_][A-Za-z0-9_.-]*$'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 2. learning_rate: uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: a5tc06pi\n",
            "Sweep URL: https://wandb.ai/bw2676-new-york-university/math_verification/sweeps/a5tc06pi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run sweep agent\n",
        "-----"
      ],
      "metadata": {
        "id": "-eWethtVSJrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_sweep():\n",
        "    trainer = MathVerificationTrainer()\n",
        "    trainer.setup_model()\n",
        "    trainer.prepare_datasets(max_samples=1000)  # Adjust based on available RAM\n",
        "    trainer.sweep()\n",
        "\n",
        "wandb.agent(sweep_id, run_sweep, count = 50)"
      ],
      "metadata": {
        "id": "kjIDgdFtXnbP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98d14e10-57fa-4105-a08a-af4a32914e2e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wqjop7ip with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate:: 1.000898848213062\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "==((====))==  Unsloth 2024.11.5: Fast Llama patching. Transformers = 4.46.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 7.5. CUDA Toolkit = 12.4.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Model loaded successfully!\n",
            "Preparing datasets...\n",
            "Datasets prepared! Train size: 900, Eval size: 100\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241110_051547-wqjop7ip</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bw2676-new-york-university/math_verification/runs/wqjop7ip' target=\"_blank\">floral-sweep-1</a></strong> to <a href='https://wandb.ai/bw2676-new-york-university/math_verification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bw2676-new-york-university/math_verification/sweeps/a5tc06pi' target=\"_blank\">https://wandb.ai/bw2676-new-york-university/math_verification/sweeps/a5tc06pi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bw2676-new-york-university/math_verification' target=\"_blank\">https://wandb.ai/bw2676-new-york-university/math_verification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/bw2676-new-york-university/math_verification/sweeps/a5tc06pi' target=\"_blank\">https://wandb.ai/bw2676-new-york-university/math_verification/sweeps/a5tc06pi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bw2676-new-york-university/math_verification/runs/wqjop7ip' target=\"_blank\">https://wandb.ai/bw2676-new-york-university/math_verification/runs/wqjop7ip</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">floral-sweep-1</strong> at: <a href='https://wandb.ai/bw2676-new-york-university/math_verification/runs/wqjop7ip' target=\"_blank\">https://wandb.ai/bw2676-new-york-university/math_verification/runs/wqjop7ip</a><br/> View project at: <a href='https://wandb.ai/bw2676-new-york-university/math_verification' target=\"_blank\">https://wandb.ai/bw2676-new-york-university/math_verification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241110_051547-wqjop7ip/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Run wqjop7ip errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py\", line 165, in __getattr__\n",
            "    return self.__getitem__(key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
            "    return self._items[key]\n",
            "KeyError: 'learning_rate'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "    self._function()\n",
            "  File \"<ipython-input-23-5928de349bdd>\", line 5, in run_sweep\n",
            "    trainer.sweep()\n",
            "  File \"<ipython-input-21-2e73145818d3>\", line 157, in sweep\n",
            "    learning_rate=config.learning_rate,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py\", line 167, in __getattr__\n",
            "    raise AttributeError(\n",
            "AttributeError: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'learning_rate'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run wqjop7ip errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py\", line 165, in __getattr__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.__getitem__(key)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._items[key]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m KeyError: 'learning_rate'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The above exception was the direct cause of the following exception:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-23-5928de349bdd>\", line 5, in run_sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.sweep()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-21-2e73145818d3>\", line 157, in sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     learning_rate=config.learning_rate,\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_config.py\", line 167, in __getattr__\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise AttributeError(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m AttributeError: <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'learning_rate'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cdo0jvh0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgradient_accumulation_steps: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate:: 1.0002974685132109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tper_device_train_batch_size: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "==((====))==  Unsloth 2024.11.5: Fast Llama patching. Transformers = 4.46.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 7.5. CUDA Toolkit = 12.4.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Model loaded successfully!\n",
            "Preparing datasets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get final result\n",
        "---"
      ],
      "metadata": {
        "id": "DSV3PgSEZzXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    try:\n",
        "        set_seeds()\n",
        "        print(\"Starting training pipeline...\")\n",
        "\n",
        "        # Initialize and run trainer\n",
        "        trainer = MathVerificationTrainer()\n",
        "        trainer.setup_model()\n",
        "        trainer.prepare_datasets(max_samples=1000)  # Adjust based on available RAM\n",
        "        trainer.train()\n",
        "        trainer.create_submission()\n",
        "\n",
        "        print(\"Training pipeline completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Fatal error in main: {str(e)}\")\n",
        "        raise\n",
        "    finally:\n",
        "        clear_memory()\n",
        "        print_gpu_utilization()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "TFcIHpQQaEv4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}